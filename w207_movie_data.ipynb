{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "971d3bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "flexible-passenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup = BeautifulSoup(html, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "classified-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup = BeautifulSoup(html, features=\"xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7256b498",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # extract links from a page, credit: https://pythonspot.com/extract-links-from-webpage-beautifulsoup/\n",
    "# # I had to <pip3 install lxml> to get this to work\n",
    "# def getLinks(url):\n",
    "#     html_page = urlopen(url)\n",
    "#     soup = BeautifulSoup(html_page, features=\"lxml\")\n",
    "#     links = []\n",
    "\n",
    "#     for link in soup.findAll('a', attrs={'href': re.compile(\"^/Movie Scripts/\")}):\n",
    "#         links.append(link.get('href'))\n",
    "\n",
    "#     return links\n",
    "\n",
    "# # this page is a list of all the movies IMSDb has on file for the Sci-Fi genre\n",
    "# print( getLinks(\"https://imsdb.com/genre/Sci-Fi\") )\n",
    "\n",
    "# # Now, we need to wade through list of links generated by getLinks and extract\n",
    "# # the urls for just the scripts, like is down below:\n",
    "\n",
    "# # this is just the script of a movie\n",
    "# URL = \"https://imsdb.com/scripts/12-Monkeys.html\"\n",
    "# page = requests.get(URL)\n",
    "\n",
    "# soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "# script = soup.find('pre')\n",
    "\n",
    "# # print(script.text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed52850f",
   "metadata": {},
   "source": [
    "### Uncomment the line below if you change the scraped genre in the scrape_scripts.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "212ed96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python scrape_scripts.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b196224",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(script.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80c47a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blackpanther = \"https://imsdb.com/scripts/Black-Panther.html\"\n",
    "# page_bp = requests.get(blackpanther)\n",
    "\n",
    "# soup_bp = BeautifulSoup(page_bp.content, \"html.parser\")\n",
    "# script_bp = soup_bp.find('pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f03aa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(script_bp.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4c75aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install convokit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5313dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from convokit import Corpus, download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9587695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus = Corpus(filename=download(\"movie-corpus\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c21aab09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd2466df",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = \"scripts.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5916ee87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 6540867 characters\n"
     ]
    }
   ],
   "source": [
    "# Read, then decode for py2 compat.\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it\n",
    "print('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5866cd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quentin Tarantino's\r\n",
      "\r\n",
      "                         R E S E R V O I R   D O G S\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "       October 22, 1990\r\n",
      "\r\n",
      "                               -----------------\r\n",
      "\r\n",
      "\r\n",
      "       This movie is dedicated to these following sources of\r\n",
      "\r\n",
      "       inspi\n"
     ]
    }
   ],
   "source": [
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d5e9229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = open(\"movie-corpus/corpus.json\")\n",
    "# datum = json.load(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7779368b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus = json_normalize(datum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d913ee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50f79555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# script_bp = script_bp.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f5af453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44d367c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 unique characters\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text.strip()))\n",
    "print('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "481f4a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_texts = ['abcdefg', 'xyz']\n",
    "\n",
    "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1e6d83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_from_chars = preprocessing.StringLookup(\n",
    "    vocabulary=list(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c38291a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[62, 63, 64, 65, 66, 67, 68], [85, 86, 87]]>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = ids_from_chars(chars)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a00700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(), invert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "556b5bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = chars_from_ids(ids)\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2979434e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'abcdefg', b'xyz'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.reduce_join(chars, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4faf2311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_from_ids(ids):\n",
    "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb9c9e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6540867,), dtype=int64, numpy=array([49, 82, 66, ..., 53, 50, 37])>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
    "all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9bbc1282",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6863f531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q\n",
      "u\n",
      "e\n",
      "n\n",
      "t\n",
      "i\n",
      "n\n",
      " \n",
      "T\n",
      "a\n",
      "r\n",
      "a\n",
      "n\n"
     ]
    }
   ],
   "source": [
    "for ids in ids_dataset.take(13):\n",
    "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "802a3931",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//(seq_length+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b5e3297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64761"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3bc320b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'Q' b'u' b'e' b'n' b't' b'i' b'n' b' ' b'T' b'a' b'r' b'a' b'n' b't'\n",
      " b'i' b'n' b'o' b\"'\" b's' b'\\r' b'\\n' b'\\r' b'\\n' b' ' b' ' b' ' b' ' b' '\n",
      " b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' '\n",
      " b' ' b' ' b' ' b' ' b' ' b' ' b'R' b' ' b'E' b' ' b'S' b' ' b'E' b' '\n",
      " b'R' b' ' b'V' b' ' b'O' b' ' b'I' b' ' b'R' b' ' b' ' b' ' b'D' b' '\n",
      " b'O' b' ' b'G' b' ' b'S' b'\\r' b'\\n' b'\\r' b'\\n' b'\\r' b'\\n' b'\\r' b'\\n'\n",
      " b'\\r' b'\\n' b'\\r' b'\\n' b'\\r' b'\\n' b'\\r' b'\\n' b'\\r' b'\\n' b' ' b' '\n",
      " b' ' b' ' b' ' b' ' b' ' b'O'], shape=(101,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for seq in sequences.take(1):\n",
    "    print(chars_from_ids(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "369dced8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"Quentin Tarantino's\\r\\n\\r\\n                         R E S E R V O I R   D O G S\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n       O\"\n",
      "b'ctober 22, 1990\\r\\n\\r\\n                               -----------------\\r\\n\\r\\n\\r\\n       This movie is dedicat'\n",
      "b'ed to these following sources of\\r\\n\\r\\n       inspiration:\\r\\n\\r\\n\\r\\n                               TIMOTHY C'\n",
      "b'AREY\\r\\n\\r\\n                                ROGER CORMAN\\r\\n\\r\\n                                ANDRE DeTOTH\\r'\n",
      "b'\\n\\r\\n                                CHOW YUEN FAT\\r\\n\\r\\n                               JEAN LUC GODDARD\\r\\n'\n"
     ]
    }
   ],
   "source": [
    "for seq in sequences.take(5):\n",
    "    print(text_from_ids(seq).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "053ef353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "11776685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
       " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_input_target(list(\"Tensorflow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "96903fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "900abd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : b\"Quentin Tarantino's\\r\\n\\r\\n                         R E S E R V O I R   D O G S\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n       \"\n",
      "Target: b\"uentin Tarantino's\\r\\n\\r\\n                         R E S E R V O I R   D O G S\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n       O\"\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
    "    print(\"Target:\", text_from_ids(target_example).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e313db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "BUFFER_SIZE = 1000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a70f1e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "        super().__init__(self)\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                   return_sequences=True, \n",
    "                                   return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        x = inputs\n",
    "        x = self.embedding(x, training=training)\n",
    "        if states is None:\n",
    "            states = self.gru.get_initial_state(x)\n",
    "        x, states = self.gru(x, initial_state=states, training=training)\n",
    "        x = self.dense(x, training=training)\n",
    "\n",
    "        if return_state:\n",
    "            return x, states\n",
    "        else: \n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3983b722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c826c96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(\n",
    "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
    "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6cb2bb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 97) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3725cbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  24832     \n",
      "                                                                 \n",
      " gru (GRU)                   multiple                  3938304   \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  99425     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,062,561\n",
      "Trainable params: 4,062,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "afb6c0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f49b0147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11, 23, 86, 68, 82, 44, 92, 46,  4, 42, 24, 82, 23, 56, 18, 12, 34,\n",
       "       78, 27, 48, 30,  3, 36, 71, 42, 93, 27, 60, 53,  1, 49, 91,  5, 37,\n",
       "       55, 13, 69,  6, 21, 67, 95, 58, 76,  5, 10, 62, 19, 21, 63, 38, 54,\n",
       "        9, 85,  5,  1, 65, 23, 33, 85, 32,  5, 11, 11, 41, 47, 69, 25, 17,\n",
       "       38, 64, 49, 57, 54, 73, 67, 26, 88,  8, 87, 36, 42, 90, 90, 60, 30,\n",
       "       85, 89,  5, 25, 75, 25, 74, 39, 76, 91, 44, 12, 58, 92, 49])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1a88089f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " b'.\\r\\n\\r\\n                              MR. WHITE\\r\\n                 You talked to Nice Guy Eddie?  Why\\r\\n '\n",
      "\n",
      "Next Char Predictions:\n",
      " b'\\'5yguL\\xc2\\x9dN J6u5X0(Bq9P=\\rDjJ\\xc2\\xab9]U\\tQ\\xc2\\x9c!EW)h\"3f\\xc2\\xbdZo!&a13bFV%x!\\td5Ax?!\\'\\'IOh7/FcQYVlf8}$zDJ\\xc2\\x98\\xc2\\x98]=x\\xc2\\x80!7n7mGo\\xc2\\x9cL(Z\\xc2\\x9dQ'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2f86f2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0eb695c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 97)  # (batch_size, sequence_length, vocab_size)\n",
      "Mean loss:         4.5745244\n"
     ]
    }
   ],
   "source": [
    "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
    "mean_loss = example_batch_loss.numpy().mean()\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "564fc925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.9819"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.exp(mean_loss).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5575013e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5b3b3a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './deneme2'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ea5ed368",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "# with 2 epochs, loss is 1.5116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a6d09a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1011/1011 [==============================] - 3358s 3s/step - loss: 0.9608\n",
      "Epoch 2/20\n",
      "1011/1011 [==============================] - 2818s 3s/step - loss: 0.8225\n",
      "Epoch 3/20\n",
      "1011/1011 [==============================] - 2857s 3s/step - loss: 0.7336\n",
      "Epoch 4/20\n",
      "1011/1011 [==============================] - 2825s 3s/step - loss: 0.6589\n",
      "Epoch 5/20\n",
      "1011/1011 [==============================] - 2790s 3s/step - loss: 0.5995\n",
      "Epoch 6/20\n",
      "1011/1011 [==============================] - 2785s 3s/step - loss: 0.5582\n",
      "Epoch 7/20\n",
      "1011/1011 [==============================] - 2794s 3s/step - loss: 0.5317\n",
      "Epoch 8/20\n",
      "1011/1011 [==============================] - 2773s 3s/step - loss: 0.5153\n",
      "Epoch 9/20\n",
      "1011/1011 [==============================] - 2760s 3s/step - loss: 0.5056\n",
      "Epoch 10/20\n",
      "1011/1011 [==============================] - 2748s 3s/step - loss: 0.5011\n",
      "Epoch 11/20\n",
      "1011/1011 [==============================] - 2752s 3s/step - loss: 0.4980\n",
      "Epoch 12/20\n",
      "1011/1011 [==============================] - 2760s 3s/step - loss: 0.4972\n",
      "Epoch 13/20\n",
      "1011/1011 [==============================] - 2756s 3s/step - loss: 0.4979\n",
      "Epoch 14/20\n",
      "1011/1011 [==============================] - 2743s 3s/step - loss: 0.4997\n",
      "Epoch 15/20\n",
      "1011/1011 [==============================] - 2736s 3s/step - loss: 0.5024\n",
      "Epoch 16/20\n",
      "1011/1011 [==============================] - 2801s 3s/step - loss: 0.5078\n",
      "Epoch 17/20\n",
      "1011/1011 [==============================] - 2793s 3s/step - loss: 0.5136\n",
      "Epoch 18/20\n",
      "1011/1011 [==============================] - 2820s 3s/step - loss: 0.5174\n",
      "Epoch 19/20\n",
      "1011/1011 [==============================] - 2800s 3s/step - loss: 0.5243\n",
      "Epoch 20/20\n",
      "1011/1011 [==============================] - 3288s 3s/step - loss: 0.5295\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "42ef898c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "    def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "        super().__init__()\n",
    "        self.temperature=temperature\n",
    "        self.model = model\n",
    "        self.chars_from_ids = chars_from_ids\n",
    "        self.ids_from_chars = ids_from_chars\n",
    "\n",
    "    # Create a mask to prevent \"\" or \"[UNK]\" from being generated.\n",
    "        skip_ids = tf.constant([[0], [0]], dtype=tf.int64)\n",
    "        tmp1 = tf.reshape(skip_ids, shape=(-1,))\n",
    "        uniques, idx, counts = tf.unique_with_counts(tmp1)\n",
    "        uniques_ids = tf.expand_dims(uniques, axis=1)\n",
    "        \n",
    "        sparse_mask = tf.SparseTensor(\n",
    "    # Put a -inf at each bad index.\n",
    "                values=[-float('inf')] * len(uniques_ids),\n",
    "                indices=uniques_ids,\n",
    "    # Match the shape to the vocabulary\n",
    "                dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "        print(sparse_mask)\n",
    "        \n",
    "#         #skip_ids = self.ids_from_chars(['','[UNK]'])[:, None]\n",
    "#         sparse_mask = tf.SparseTensor(\n",
    "#         # Put a -inf at each bad index.\n",
    "#             values=[-float('inf')]*len(skip_ids),\n",
    "#             indices = skip_ids,\n",
    "#         # Match the shape to the vocabulary\n",
    "#             dense_shape=[len(ids_from_chars.get_vocabulary())]) \n",
    "\n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "    @tf.function\n",
    "    def generate_one_step(self, inputs, states=None):\n",
    "    # Convert strings to token IDs.\n",
    "        input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "        input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "    # Run the model.\n",
    "    # predicted_logits.shape is [batch, char, next_char_logits] \n",
    "        predicted_logits, states =  self.model(inputs=input_ids, states=states, \n",
    "                                          return_state=True)\n",
    "    # Only use the last prediction.\n",
    "        predicted_logits = predicted_logits[:, -1, :]\n",
    "        predicted_logits = predicted_logits/self.temperature\n",
    "    # Apply the prediction mask: prevent \"\" or \"[UNK]\" from being generated.\n",
    "        predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "    # Sample the output logits to generate token IDs.\n",
    "        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "    \n",
    "    # Convert from token ids to characters\n",
    "        predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "    # Return the characters and model state.\n",
    "        return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3a45d189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor([[0]], shape=(1, 1), dtype=int64), values=tf.Tensor([-inf], shape=(1,), dtype=float32), dense_shape=tf.Tensor([97], shape=(1,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ec7db3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N'JOBU:\r\n",
      "Beach another steple oo A donton at a smilf berond.\r\n",
      "\r\n",
      "                         HUNSECKER\r\n",
      "                   (smartly)\r\n",
      "            Susie, he nob, Sodrice.\r\n",
      "\r\n",
      "HUSSETAR SUSAN\r\n",
      "\r\n",
      "            A supphone from conicesteric the wilited which dead.  Sidney colver.\r\n",
      "                   (clauf)\r\n",
      "            All that just co.  Hello?\r\n",
      "\r\n",
      "EXT. BRBUTHO, Now you square\r\n",
      "CAMERA shokeches her hadge.\r\n",
      "\r\n",
      "ROUM STADD IN  FLOW BROUR HUNSECKER\r\n",
      "\r\n",
      "Sidney darchs off and calms out, the may.  Hut is acancent,\r\n",
      "one louseng.  Where is susseal:\r\n",
      "\r\n",
      "                    NORMA\r\n",
      "                   D'Ange, J.J. it's over girl we me in\r\n",
      "            agaunt!\r\n",
      "                   (Walling)\r\n",
      "                     (lood.\r\n",
      "\r\n",
      "                     HUNSECKER\r\n",
      "                   ((pasting?)\r\n",
      "            I last, weskned to retaly.  Sidney poys to do.\r\n",
      "             out off,\r\n",
      "           Well, is a dirtation, ignowing you\r\n",
      "             hears.  What's you got thing.\r\n",
      "            expiets to worl with her, Sidney's voice.\r\n",
      "                    (franting\r\n",
      "in fear, Sidney columns up trains, her.\r\n",
      "A looks out of the say foon - teliby has befone\r\n",
      "ribl.\r\n",
      "\r\n",
      "milling:  Astred contring up the mis ard paliced, shere.\r\n",
      "\r\n",
      "                          SIDNEY\r\n",
      "                    (continuing)\r\n",
      "            Yell. Throwsidn't you'dn everything...\r\n",
      "\r\n",
      "Ises the garpy shoot, Susan is air.  The fece is foreground.  CAMERA\r\n",
      "\r\n",
      "Sidney with on one\r\n",
      "face risinuts in,  Riday\r\n",
      "\" pocko.  Now her inst out.  The shreets Sidney movis and which rectively:\r\n",
      "\r\n",
      "                       PHELL\r\n",
      "                   DsAmwit.  he rabugies the blud.  He ladges.\r\n",
      "            Susie.  He wirlows Sobenten, and\r\n",
      "            mact vury cutting.  They's\r\n",
      "             you miff.  Just he is shut is\r\n",
      "             all to do.  He can's be the\r\n",
      "            his continu?!\r\n",
      "\r\n",
      "LESUME HUNSECKER - FISEd BACK Steve folws.\r\n",
      "\r\n",
      "                         HUNSECKER\r\n",
      "                   Sus, \"Lore photeder there so\r\n",
      "            hearces to Susan, so hood that\r\n",
      "            (puttlepically)\r\n",
      "            Wolk to do atent....  Husice he waites -\r\n",
      "\r\n",
      "                        HUNSECKER\r\n",
      "                   (convining)\r\n",
      "             You didin't will pintly turn in fain - tho\r\n",
      "            contrinu!s.\r\n",
      "\r\n",
      "CANGERO  HUNSECKERAGE ANGLE (He villings sibm-to\r\n",
      "he screfucals a girl. ANA\r\n",
      "Honterd.  Brocks iff in so, He is wripiswer. Temple outhor Necord\r\n",
      "to ask agases:\r\n",
      "\r\n",
      "                               HUNSECKER\r\n",
      "                   Mavia.  What'velly me!\r\n",
      "                   SUSAN\r\n",
      "                   (a could)\r\n",
      "             Your youn youn Mry.\r\n",
      "                   (helle! (He rights)\r\n",
      "            You sat them, you tom main is she pencons up\r\n",
      "Sidney to strat like off him.\r\n",
      "\r\n",
      "\r\n",
      "                     SUSAN\r\n",
      "                    (chosely)\r\n",
      "            No, 's same, Bleasine he suppices - a join\r\n",
      "             affact.  See you butten!\r\n",
      "\r\n",
      "Ho sees a deddonted pause, conving really. she'sless\r\n",
      "haspentherting one spet of a nadders yeal arb.\r\n",
      "\r\n",
      "Hunsecker gees up but he warks her for cab, looking to phone:..CAMERA INT her.\r\n",
      "\r\n",
      "                       SIDNEY\r\n",
      "              (continuntly)\r\n",
      "            On the agtione to the call and you, Mr...\r\n",
      "\r\n",
      "                      HUNSECKER\r\n",
      "            Just - Kello has asted his\r\n",
      "            deed imporitt?  Walk to Sidney or feel\r\n",
      "            sits... Gut is Gill THEnse.  You - CAMERA\r\n",
      "            Sherid barbly a found on Maly - he\r\n",
      "            too beew....Dregent.  Borying and his CAmu,\r\n",
      "            you to stade.\r\n",
      "\r\n",
      "                           haven't dot's in fearmout.  Sidney dest as\r\n",
      "            the foor who do a cain to you badrots.\r\n",
      "                   (cas head)\r\n",
      "                    (to Silly)\r\n",
      "            I want do wartadato...\r\n",
      "\r\n",
      "Sidney's comoration; Susan as he begins Stevit, he slee.\r\n",
      "\r\n",
      "                      THAPERA KUYA\r\n",
      "            Sidney leaves a darible lightly.\r\n",
      "\r\n",
      "                    ROSSES\r\n",
      "                   D'Angelo's wiff a hearry --\r\n",
      "            Evere's renumons, a\r\n",
      "            miling, She's nettie)\r\n",
      "            Cheselone, we'reso the ind...\r\n",
      "\r\n",
      "Hunsecker promections are are\r\n",
      "Sidney, askraps the tax in the waiter...\r\n",
      "\r\n",
      "            BURTHA\r\n",
      "\r\n",
      "                   PHIL\r\n",
      "            He pauses very and to ofwer the second\r\n",
      "intimat, with Hunsecker, calfing the ligit, in\r\n",
      "squares behond\r\n",
      "agent and fored.  Thel priny wild and fulls walkn is foesalow who stat\r\n",
      "by but they pickul in foregrsal and onanget way he usans are\r\n",
      "the door; she passes his ense and is acrest; but shaticollist on his eyes of\r\n",
      "hew Bryond up. He cabrys to see the upen, down at the doon tops with\r\n",
      "            Susane.\r\n",
      "            staps up, well ranly on\r\n",
      "them then at the eleves her.\r\n",
      "\r\n",
      "                        BALLY\r\n",
      "                   (around)\r\n",
      "             You't of yon't mement again.\r\n",
      "\r\n",
      "                           HUNSECKER\r\n",
      "                   (continuing)\r\n",
      "             (poss) girl)\r\n",
      "            Lot reveal is nerd to to would, munsed you he'll\r\n",
      "             it's they room to Kello and both eshisuet.  EVARI\r\n",
      "            As it.  I've - come felling,\r\n",
      "            fain were - you're go move!\r\n",
      "\r\n",
      "                   SIVNEY\r\n",
      "                  Yes, hape, J.J., there's.\r\n",
      "\r\n",
      "Steve to see her does of what he lide he wait, club, she midsien the\r\n",
      "goes of pushes on the firstrently, with\r\n",
      "comelate Sidney has beforred lefvest and sleft\r\n",
      "umparamer to stanted. THe begronistly on, her\r\n",
      "           whotey?  I don't let garneato \"\r\n",
      "            Delohget it, car comen up meline that In\r\n",
      "left a fearstands, let an eye...\r\n",
      "\r\n",
      "TVEST HUPSIDE SUSAN\r\n",
      "\r\n",
      "                                HUSSECKER\r\n",
      "                  (likely)\r\n",
      "             If you buty.  We look me son it.\r\n",
      "                   (Surning, that that up.)\r\n",
      "            Desay is lowfere.  Hunsecker from\r\n",
      "            naming to mare!  He moves biggle\r\n",
      "            gunting, gleas asteredly)\r\n",
      "           J.J...Hunsecker...\r\n",
      "\r\n",
      "REVELSE UP - BASKE\r\n",
      "\r\n",
      "Frank looking door on    in he with to -bad them ack...\r\n",
      "\r\n",
      "Susan looks dowards this is clattely in\r\n",
      "she masting at Guy's voice helple\r\n",
      "espittent his gigsisly\r\n",
      "utearidet.  A cut fige up its, \"ashesef as and standing the\r\n",
      "\r\n",
      "                       down onto the barna beloses.  All lvops Hunsecker's\r\n",
      "             oncomind.Gratt...\r\n",
      "\r\n",
      "                      HUNNE\r\n",
      "             I pat here?\r\n",
      "\r\n",
      "                     GILLIS\r\n",
      "            She door tellechanted?\r\n",
      "            I'm left you who mounthys of a stagin in his\r\n",
      "           chriat stoils he --\r\n",
      "\r\n",
      "                   SUSAN\r\n",
      "                   (quietly)\r\n",
      "            Sime.  We seigly her meauthored!...\r\n",
      "\r\n",
      "\r\n",
      "           HUNSECKER\r\n",
      "                  (room.\r\n",
      "\r\n",
      "Sidney.  Sodner and me now, away walks up to annen...\r\n",
      "\r\n",
      "Sidney emented again.\r\n",
      "\r\n",
      "                        HUNSECKER\r\n",
      "            Walt, to Sidney need - that's like mo\r\n",
      "            fail.)\r\n",
      "\r\n",
      "LONG STEVE\r\n",
      "\r\n",
      "Ferpile and restants:\r\n",
      "\r\n",
      "                      SIDNEY\r\n",
      "                   (peepling)\r\n",
      "            You'd the give.  Mary.  Of\r\n",
      "            CLUB CIVER.  Pill on\r\n",
      "            closhisast fall)\r\n",
      "           SuCan is reter.  Huty suts be\r\n",
      "what SIDNEY ANGLE\r\n",
      "\r\n",
      "We s!e,.  Keon's in in alone.\r\n",
      "\r\n",
      "                          STEVE\r\n",
      "            You think you, like heild yal we - J.J.\r\n",
      "                         (feentaxity)\r\n",
      "            I'm gont in fron on him...\r\n",
      "\r\n",
      "REVERSE ANGLE\r\n",
      "\r\n",
      "She theresking as on ore\r\n",
      "gents across the doors of him, part...whooring fellishing\r\n",
      "spating across pricuse, he scene - she issuitine\r\n",
      "Huncelkey insubting.  He reaching:\r\n",
      "\r\n",
      "                            Ske the wass on it, KELLOO - D'Angelo, Dewalded\r\n",
      "            them, still glens aw you, Kellos.\r\n",
      "\r\n",
      "Pellorful Corringes on CLOSE.  Hunsecker. ...\r\n",
      "\r\n",
      "Hunsecker is just his look at the door is a tridection bear, and slahing he bock.  This is he\r\n",
      "littression'd lime answer, saventer; beanniff to snift towards the\r\n",
      "dantligly up a pocket wele, he little moves appraventairly\r\n",
      "            feg intodtedn the good samiscase.  Susin't\r\n",
      "            but wet a territoul contar.  with\r\n",
      "fireground, looks at he shalks butsing untervoing, is seentings.\r\n",
      "\r\n",
      "REVERSELA\r\n",
      "\r\n",
      "Rita waits them being on the streight but\r\n",
      "bigge like ho chat.  Bet your shok for S... d'stanter.\r\n",
      "\r\n",
      "           throng, the Pello Daby Swend.  As the inardle sayf\r\n",
      "someshoutied, wait buticlly busing\r\n",
      "from three that juit in mead...\r\n",
      "\r\n",
      "HUNSECKER\r\n",
      "\r\n",
      "The man is us from on her; dusho.\r\n",
      "\r\n",
      "            He heres her cooted.  Then good rall, thin is\r\n",
      "they walking to the ward as He dains stands:\r\n",
      "\r\n",
      "REVERSE THA GEVE - NIGLT\r\n",
      "\r\n",
      "He is quiet paind them in out.  The door contiencely.\r\n",
      "   Ex te pean in Hincenow, smear\r\n",
      "tooffull of the walls, and then the trick and Sidney\r\n",
      "unse are a reactur of a probace coat back.  As he falls a ridfwense very.\r\n",
      "Then fehind her, sceer into Sidney takes now.  The\r\n",
      "looks at STEVE, custioning reper this goes in a\r\n",
      "from CAMERA PANSS of Sidney coming somether end\r\n",
      "falls s reaccup.  There looks a little scroally lows the sand and enjory of\r\n",
      "           way you....\r\n",
      "\r\n",
      "Wo SHE poothing.  Padat A CAMERT, Nommy.\r\n",
      "\r\n",
      "                         HUNSECKER\r\n",
      "                    (togething)\r\n",
      "            I wasan tonelco.        (- compries to a grooutly)\r\n",
      "reamone.  Keop    gets apives,...\r\n",
      "\r\n",
      "STOVE\r\n",
      "\r\n",
      "Ranxaully breaks the pain.  He walks stoat....across for the windoand Yount newself in head\r\n",
      "sidnied.  He looks at her off fee.  She hangs into a muncum back of Susan:\r\n",
      "\r\n",
      "                       SIDNEY\r\n",
      "            Higs.  Look you're that me so\r\n",
      "            eyem ann firugh which and he hear tou?\r\n",
      "            Not in then so petcy.  The\r\n",
      "             poot -band for giving far and we\r\n",
      "             ad!  You're like o8!\r\n",
      "\r\n",
      "TE E DVAnk at that the soment ag an only three open around Hunscause.\r\n",
      "\r\n",
      "                        SUMAN\r\n",
      "              (and - which recruces again with\r\n",
      "            inten it the cigured fager!\r\n",
      "\r\n",
      "INT. OF HEV, leck up his heirly and ceres.\r\n",
      "\r\n",
      "                       The bessob get instabteret\r\n",
      "            innerst in.  Atidy-you're thing up\r\n",
      "            little in the floored boy?  There's\r\n",
      "            pretsme...o\r",
      "NE gram an a plair table.\r\n",
      "\r\n",
      "INT. BETWYLO'D CARPE\"THY\r\n",
      "\r\n",
      "Sidney's like yourse forrowla you plan we roin\r\n",
      "in \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 26.63539695739746\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['N\\'JOBU:'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(10000):\n",
    "    next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "    result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "\n",
    "print(f\"\\nRun time: {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dc0c3c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-network",
   "metadata": {},
   "source": [
    "next steps: find nonsense words, count num nonsense/normal words --> success metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-sentence",
   "metadata": {},
   "source": [
    "Code used: [the original script](https://github.com/tarik3333/Movie-script-gen/blob/main/Untitled9.ipynb) and [this answer](https://stackoverflow.com/questions/68939916/tensorflow-text-generation-rnn-example-failing-on-tf-2-6-tf-sparse-to-dense)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
