import requests
import re
from bs4 import BeautifulSoup
from urllib.request import Request, urlopen
from urllib.parse import urljoin

# I had to <pip3 install lxml> to get this to work
def getLinks(url, pattern):
    """From the page of <genre> movies, make a list of URLS for each movie page
    credit: https://pythonspot.com/extract-links-from-webpage-beautifulsoup/"""
    html_page = urlopen(url)
    soup = BeautifulSoup(html_page, features="lxml")
    links = []

    for link in soup.findAll('a', attrs={'href': re.compile(pattern)}):
        links.append(link.get('href'))

    return links

def getMoviePages():
    """Edit the getMovies list of URLS to be in a form we can "click" on"""
    genreURL = "https://imsdb.com/genre/Sci-Fi"
    pattern = "^/Movie Scripts/"
    moviepages = []
    for i, url in enumerate(getLinks(genreURL, pattern)):
        url = re.sub(" ", "%20", url)
        moviepages.append(urljoin(genreURL, url))

    return moviepages

def getScriptLinks():
    """for some reason this outputs duplicate links and takes hella long to run?"""
    pattern = "/scripts/"
    script_links = []
    for i, url in enumerate(getMoviePages()):
        script_links.append(getLinks(url, pattern))

    rootURL = 'https://imsdb.com'
    for i, url in enumerate(script_links):
        script_links[i] = urljoin(rootURL, url) ## struggling to concatonate, help??

    return script_links

#print(getMoviePages())
print(getScriptLinks())



# Now, we need to wade through list of links generated by getMovies and extract
# the urls for just the scripts, like is down below:

# this is just the script of a movie
# URL = "https://imsdb.com/scripts/12-Monkeys.html"
# page = requests.get(URL)
#
# soup = BeautifulSoup(page.content, "html.parser")
# script = soup.find('pre')

# print(script.text.strip())
